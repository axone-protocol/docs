---
sidebar_position: 7
---

# Use cases

## 1. OKP4: Pioneering a sustainable revolution in Carbon Credit Management

### Context

Carbon credits are certificates governments or international entities issued that allow companies to offset their greenhouse gas emissions. Each credit corresponds to one ton of CO2 avoided. Companies can purchase these credits to achieve their carbon neutrality goals. They also support environmental projects aimed at reducing future emissions. Thus, carbon credits represent an essential tool in combating climate change. They are relevant to all sectors of activity, including industry, aerospace, agriculture, agri-food, institutions, etc. Key issues are potentially slowing down or will slow down this sustainable revolution in Carbon credit:

- There is **a lack of interoperability of systems**; it breaks the consolidation of information in a global approach.
- There is **a lack of transparency** from companies regarding the calculation method.
- There is a severe **risk of double accounting** of credit carbon or greenwashing (false claims, fake green credentials, etc.)
- Financial and institutional infrastructures in the carbon market need transparency to bring trust.
- There are regulatory issues (risk of manipulation, fraud, speculation, etc.)

### Storytelling

Calculating greenhouse gas emissions seemed like an overwhelming task. Different methods like GHG Protocol, Verified Carbon Standard (VCS), and Gold Standard are used, and the market has to face many critical issues (see above).

OKP4 Protocol automates data collection, processing, and analysis and simplifies complex workflows. Energy consumption, transportation, industrial processes—data from various sources can now be seamlessly gathered and aggregated.

Transparency and traceability shine through as the protocol allows stakeholders to track each step, ensuring data authenticity and fostering trust. The reliability of carbon credits is further bolstered by the integrated verification mechanism, protecting against manipulation, errors, and falsification.

Additional carbon data sharing, verification, and official registration workflows eliminate the risk of double accounting, creating a fair and reliable system. Continuous monitoring goes beyond point-in-time calculations, allowing trends to be detected and targeted measures to be implemented.

Fuel consumption, direct emissions, electricity usage, and business travel are just some examples of the data that can be collected. The OKP4 protocol opens the door to a wealth of information, empowering organizations to make informed decisions and identify opportunities for emission reduction.
This holistic approach fosters trust among stakeholders and encourages a widespread knowledge exchange.

The scalability of the OKP4 protocol ensures it evolves with regulatory changes and embraces new data sources. It becomes the cornerstone of a sustainable future where environmental responsibility meets technological innovation.

Interoperability ceases to be a concern as the protocol effortlessly integrates complex workflows and eliminates compatibility issues.

### [Market](https://www.globenewswire.com/en/news-release/2023/04/18/2648655/0/en/Carbon-Offset-Carbon-Credit-Market-Size-Projected-to-Reach-1-602-7-Billion-by-2028-MarketsandMarkets.html)

The global Carbon Credit Market is projected to grow remarkably, from USD **414.8 billion in 2023 to USD 1,602.7 billion by 2028, with a staggering CAGR of 31.0%.** This exponential growth reflects the growing recognition of the importance of carbon offsetting in combating climate change and achieving net-zero greenhouse gas emissions.

The global Carbon Offset/Carbon Credit Market is poised for remarkable growth in the coming years. Increasing awareness, investments in carbon capture technologies, and the rise of impactful projects drive this market expansion. By participating in carbon offsetting, OKP4 is part of a global effort to combat climate change while creating a more sustainable and resilient future for all.

### How does it work? Input & output

***Typical workflow:***

1. **Data Collection** from various sources (ERP, CSR, etc.), actors (suppliers, clients, etc.), and formats (IoT sensors, meters, energy management systems, etc.)
2. **Aggregation and normalization** conversion services, standardization, quality, joining services)
3. **Processing and calculation** (GHG Protocol, VCS Protocol, Gold Standard, reference data, conversion factors) under different categories (scope 1: direct emissions, scope 2: energy-related indirect emissions, scope 3: upstream and downstream indirect emissions)
4. **Analysis and reporting** (additional analysis based on the usage of the results, detailed and automated reporting to identify significant sources, trends, and reduction opportunities). Providing access to public and economic actors.
5. **Offsetting**: Carbon data sharing, verification, and registration in the official registry. This avoids double accounting of credits in parallel! The protocol enables continuous monitoring beyond point-in-time calculations to detect trends and implement measures.

### And tomorrow?

OKP4 protocol is promising, potentially becoming a widely adopted, standardized, and technologically advanced framework for carbon credit calculation and management. Its impact can extend beyond individual organizations, contributing to global efforts in combating climate change, achieving sustainable development goals worldwide, and ensuring fair revenue for participants. The protocol allows, at the same time, incentives organizations to share their better-quality data and create new business models.

## 2. Transparent & Fair Model Training (Ml & AI)

### Context

Nowadays, AI-based programs are black boxes. We don't know how and on what data they are trained. It's a lack of transparency for end-users. Furthermore, those who provide the data don't know about the usage and get no value for sharing.
AI needs more trust, audibility, ethical systems, bias detection, and compliance with regulations like the [EU IA Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A52021PC0206) to gain its full potential. A decentralized approach seems obvious. But which solution to bring it?

### Storytelling

***When you use ChatGPT or any AI application, do you know where data comes from?***

 Absolutely not. Maybe companies like ***OpenAI*** have value thanks to some data YOU provided, but you don't know it. And you don't profit from revenue splitting.

***Here comes OKP4 Protocol.***

 Anyone can submit resources (dataset, algorithms, infrastructure, etc.) and rules to use it. Anyone can ask for model training from multiple resources. The protocol controls the conditions and triggers validations. Every single execution is tracked and stored immutably in the blockchain. OKP4 protocol ensures traceability but also enforces revenues for data providers.

***A bright future for AI.***

 OKP4 Protocol brings an innovative "open source" training approach with fair and transparent revenue sharing. It unlocks the potential of new powerful AI applications, braked with inconsistency and uncertainty.

 Multiple user interfaces can be quickly built upon the protocol to bring significant user experience regarding Machine-Learning models trained through OKP4.

 Less centralized control also means strengthening the democratic process, as any citizen doesn't have to trust private (and capitalized) entities to get to grips with the new world opened up by AI.

 OpenAI Inc. offers grants "[to fund experiments in setting up a democratic process for deciding what rules AI systems should follow](https://openai.com/blog/democratic-inputs-to-ai)". OKP4 protocol can guarantee the storage and enforcement of the defined rules.

### [Market](https://www.statista.com/statistics/1365145/artificial-intelligence-market-size/#:~:text=According%20to%20Next%20Move%20Strategy,a%20vast%20number%20of%20industries)

Transparency issues apply to the whole field of AI. According to [Next Move Strategy Consulting](https://www.nextmsc.com/), the artificial intelligence market is expected to grow strongly in the coming decade. Its nearly $100 Billion U.S. value is expected to grow twentyfold by 2030, up to almost two trillion U.S. dollars. The AI market covers a vast number of industries. Everything from supply chains, marketing, product making, research, analysis, and more are fields that will, in some aspect, adopt artificial intelligence within their business.

### How it works, input & output

Any entity provides any source of data to train any model.
Let's take an example. Multiple media publishers could submit their newsfeeds to the protocol.
 A Machine Learning company could use specifically some of these stream data to propose a new summary. Everyone could know from which publishers the summary is from. For each summary consumption, revenue sharing is applied between every concerned publisher.

Example :

Two companies (Corp A and Corp B) grant access to their databases, while a third company (Corp C) provides a machine-learning training workflow using the data. A data scientist (Individual D) wants new knowledge and invokes an orchestration service that uses resources from Corp A, Corp B and Corp C.

The OKP4 solution orchestrates the training process without exposing raw data, ensuring privacy, sovereignty and security. Moreover, the protocol provides revenue-sharing conditions and immutable records of the ML model's training sources.

1. Each on their own, Corp A and Corp B indicate through an administration portal the underlying technology of their respective database. They store access tokens with a Secret Management Service, with authorization for orchestration service.
2. Corp A and Corp define the rules, with access restrictions and payment conditions (a fixed $KNOW fee per request, for example). They inform a maximum of metadata, especially to describe the different available datasets, their structures and the nature of their contents.
3. Metadata indicates that resources shared by Corp A and Corp B are compatible with an ML job from Corp C. Corp C submitted its training model algorithm, governance rules, and service execution instructions.
4. Individual D parameters its cloud environment, setting up how an orchestration service should store the execution request results.
5. Individual D requests service execution with the ML Workflow from Corp C, using data from Corp A and Corp B. He submits a transaction with a Keplr wallet and pays with $KNOW tokens. The blockchain validates the execution request (access and execution authorizations).
6. The orchestration service listens to the event from the blockchain. It recovers access keys and then executes the workflow training algorithm from Corp C, using Corp A & Corp B data it fetches.
7. The orchestration service tracks the progress and state changes of all jobs within the workflow and reports this information to the blockchain. If all works well, service agreement rules are applied, and $KNOW tokens from Individual D are unlocked to Corp A, Corp B, et Corp C.
8. The orchestration service stores the result in the provided Individual D's storage solution. Optionally, this new knowledge can also be referenced as a data source for other workflows. Individual D can have access to the newly generated knowledge.

### And tomorrow?

OKP4 protocol aims to be the standard for AI transparency. This structuring new process for ML training will unlock the creation of a huge set of ML applications.

## 3. Create, manage, and fully exploit organization and community governance

### Context

All organizations need help in their governance, whether on the scale of a state, a company, an association or even a community of individuals. Notions of transparency, fairness, identity, trust and representativeness are essential to good governance and are increasingly in demand by the members of these organizations. Therefore, actions and decision-making within these organizations face all these challenges and require particular, high-performance tools for optimum efficiency.
Web3 has also enabled the emergence of D.A.O. (Decentralized Autonomous Organization). These organizations overturn the paradigm of traditional structures, eliminating the need for a central authority. They operate on a decentralized basis, allowing each member to participate in decision-making. However, they also face similar challenges, which the OKP4 protocol can help to resolve, thanks in particular to its fine-tuned, personalized governance management.

### Storytelling

With OKP4, organizations finally have a solution for improving their governance management. Let's take the example of a D.A.O.: OKP4 will enable more precise governance closer to its members by optimizing the operational functioning of the D.A.O. Information monitoring, analysis of members' needs, monitoring of voting trends and projections, distribution of powers, the automated release of funds, etc. all these functionalities will help to streamline the decision-making process of organizations (decentralized or otherwise).

### [Market](https://daotimes.com/6-interesting-dao-insights-from-2022/)

Estimating the market size on a broad subject, such as organizations and communities, is difficult. Instead, let's deep dive into Decentralized Autonomous Organization (D.A.O.). As of January 2023, the total market capitalization of the D.A.O. market stood at $8.8 billion. The total number of decentralized organizations stood at an impressive 10,752, up from 4,830 organizations in three months.

### How it works, input & output

***Example of a DEX algorithmic engine update.***

A working group mandated by a community initiates discussions on a forum to improve the algorithmic remuneration model of a DEX to optimize the distribution of management fees to its clients. The group proposes a few avenues to explore and a budget envelope. Preliminary discussions take place on the forum and cross-cutting discussions via e-mail or online messaging (Telegram, WhatsApp or other).

Thanks to the protocol, the group will formalize and build an initial workflow enabling a tool for analyzing and synthesizing discussions referenced in the Dataverse. The first stage of collecting discussions is implemented. Then these are aggregated and processed using text analysis and natural language processing tools according to the needs of the working group. Then, based on this analysis, a summary is created to facilitate understanding of all this information and made accessible to all members,

Thanks to OKP4, the working group and the wider community can ensure a clearer understanding of the discussions around proposals, thus promoting more informed and transparent decision-making. Following these discussions, a vote is opened to propose an external service provider to improve the DEX engine. Within this framework, a specialized "FinTech" company is mobilized to implement its analysis models and a customized expert report for an amount previously validated by vote.

If the vote results are positive, then part of the funds are automatically released, and a project manager is identified to report on the proper execution of the work.

The service provider then carries out the work, and once it has been completed and validated, the remaining funds are released to the service provider, and a report is generated detailing the entire decision-making process and the project's progress.

## 4. Other use cases with OKP4

**IoT and PoPW network as a Service**

- **Environmental sensor network:** Manage a decentralized network for surveillance of air, water, noise, and other environmental factors.
- **Driving data:** Decentralized sensor network between vehicles to enhance traffic safety and efficiency or collect actionable vehicle data.
- **Communication network:** create a decentralized network for Wi-Fi/5G connections, or a decentralized network for satellite internet.
- **Distributed energy resource network:** Connect batteries to the network to build a sustainable energy system.

**Agriculture**

- **Irrigation optimization:** Share soil sensor data and analysis models to optimize water use according to the specific needs of crops.
- **Crop management by drone or satellite:** Share real-time data to improve decision-making, management, and thus enhance knowledge about crops.
- **Agronomic research:** Share field data to support research on new cultivation methods and plant varieties.
- **Sustainable soil management:** Share resources on soil quality and health to promote sustainable land management practices.
- **Precision agriculture:** Share field sensor data and satellite images to enable more precise and efficient agriculture.
- **Agricultural biodiversity:** Share observations on plant and animal species present in and around fields to monitor and support biodiversity.

**Health**

- **Personalized medicine:** Share data and services for genome sequencing and patient lifestyle information to tailor treatments to the individual.
- **Epidemiology:** Share public health data and analysis resources to monitor and understand the spread of diseases.
- **Coordinated care:** Share patient medical records between different care providers for coordination and continuity of care.
- **Cancer research:** Share imaging data, tumor gene expression profiles, and treatment responses to develop predictive models of cancer progression and treatment response.
- **Disease prevention:** Share information on healthy behaviors and risk factors to prevent diseases.
- **Telemedicine:** Share remote diagnostic tools and resources to improve access to care, especially in remote or underserved areas.

**Industry**

- **Predictive maintenance:** Share sensor data and analysis models to predict when equipment will need to be repaired or replaced.
- **Supply chain optimization:** Share data on inventory, demand, and delivery times to improve supply chain efficiency.
- **Product quality:** Share quality control data and analysis tools to improve product quality.
- **Process simulation:** Share production data and simulation models to optimize manufacturing processes.
- **Waste management:** Share data on waste production and tools to minimize waste production.
- **Automation:** Share production data and machine learning models to automate certain production tasks.

**AI**

- **Creation of a compute network for ML:** Allows anyone to build a computing network for ML, offering economic incentives for participation in the training of ML models.
- **Tools for verifiable and privacy-respecting ML:** Enables the training and inference of models without exposing sensitive data to the model creator.
- **Creation of specific datasets for training:** Facilitates the collaborative creation of proprietary datasets for model training.
- **DAO for managing AI models:** Envision DAOs for the management of AI models, overseeing the  entire process of model training and fine-tuning, then making it available for inferences in return for a fee.
